{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65de68b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, trange\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "try:\n",
    "    gpu = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "    tf.config.experimental.set_memory_growth(gpu[0], True)\n",
    "except:\n",
    "    print(\"Couldn't initialize gpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c0d227",
   "metadata": {},
   "source": [
    "### Import our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83cfaa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = pd.read_csv(\"../datasets/IMDB Dataset.csv\")\n",
    "fina = pd.read_csv(\"../datasets/financial-headlines.csv\")\n",
    "data = pd.concat([imdb, fina]) # combine into big"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f9b43",
   "metadata": {},
   "source": [
    "### Define our functions for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7440864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text):\n",
    "    TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "    return TAG_RE.sub(\"\", text)\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    # make lowercase\n",
    "    sentence = sen.lower()\n",
    "    \n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sentence)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    #sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", \" \", sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9627bb",
   "metadata": {},
   "source": [
    "### Process the data\n",
    "Remove all neutral scores, capitalization, tags, punctuation, single characters, multiple spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b78ade1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "data = data[data[\"sentiment\"] != \"neutral\"]\n",
    "data[\"review\"] = [preprocess_text(str(x)) for x in tqdm(data[\"review\"], leave=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b168bdd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there s a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei s love in the time of money is a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4840</th>\n",
       "      <td>helsinki thomson financial shares in cargotec ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>london marketwatch share prices ended lower in...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>operating profit fell to eur mn from eur mn in...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>net sales of the paper segment decreased to eu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>sales in finland decreased by in january while...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51967 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review sentiment\n",
       "0     one of the other reviewers has mentioned that ...  positive\n",
       "1     a wonderful little production the filming tech...  positive\n",
       "2     i thought this was a wonderful way to spend ti...  positive\n",
       "3     basically there s a family where a little boy ...  negative\n",
       "4     petter mattei s love in the time of money is a...  positive\n",
       "...                                                 ...       ...\n",
       "4840  helsinki thomson financial shares in cargotec ...  negative\n",
       "4841  london marketwatch share prices ended lower in...  negative\n",
       "4843  operating profit fell to eur mn from eur mn in...  negative\n",
       "4844  net sales of the paper segment decreased to eu...  negative\n",
       "4845  sales in finland decreased by in january while...  negative\n",
       "\n",
       "[51967 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e973e3f3",
   "metadata": {},
   "source": [
    "### Tokenize the data and split X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb030a",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df3b0af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36376, 1934) (36376, 2)\n",
      "(15591, 1934) (15591, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-4f1a53b6216b>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X_train, X_test, Y_train, Y_test = np.array(train_test_split(X,Y, test_size=test_size, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "max_features = 2000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=\" \")\n",
    "tokenizer.fit_on_texts(data[\"review\"].values)\n",
    "X = tokenizer.texts_to_sequences(data[\"review\"].values)\n",
    "X = pad_sequences(X)\n",
    "Y = pd.get_dummies(data[\"sentiment\"]).values # convert to indicator columns\n",
    "\n",
    "test_size = .3 # 70/30 train/test split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07845284",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128 # play with these\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2, recurrent_activation=\"sigmoid\"))\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer=\"adam\",metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa887d3",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 7\n",
    "model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2914bc",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247fb53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 1500\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "\n",
    "score, acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "\n",
    "print(f\"score: {score:.2f}\")\n",
    "print(f\"accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97a2839",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
    "for x in trange(len(X_validate)):\n",
    "    \n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 0)[0]\n",
    "   \n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            neg_correct += 1\n",
    "        else:\n",
    "            pos_correct += 1\n",
    "       \n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        neg_cnt += 1\n",
    "    else:\n",
    "        pos_cnt += 1\n",
    "\n",
    "print(\"pos acc\", pos_correct/pos_cnt*100, \"%\")\n",
    "print(\"neg acc\", neg_correct/neg_cnt*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f31bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
