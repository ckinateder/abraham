{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "852a3244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "from newspaper import Article, ArticleException\n",
    "from GoogleNews import GoogleNews\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re, string\n",
    "import nltk \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "from pprint import pprint\n",
    "#%matplotlib inline\n",
    "fsize = (16, 9)\n",
    "dpi = 120\n",
    "plt.rcParams.update({\"figure.figsize\": fsize, \"figure.dpi\": dpi}) # set params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a71e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenews = GoogleNews() # create news object\n",
    "search_term = \"APPLE\" # our search term\n",
    "googlenews.get_news(search_term) # get the news\n",
    "results = googlenews.results() # get the results\n",
    "\n",
    "def get_text(inst): # download the article text for each link and save as a string\n",
    "    try:\n",
    "        article = Article('http://'+inst['link'])\n",
    "        article.download()\n",
    "        article.parse()    \n",
    "        inst['text'] = article.text.strip().replace(\"\\n\",\" \")\n",
    "        \n",
    "    except ArticleException:\n",
    "        print(f\"Failed on {url}\")\n",
    "    return inst['text']\n",
    "\n",
    "processes = [] # multi thread the execution\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for i in results:\n",
    "        processes.append(executor.submit(get_text, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cef4ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(tweet_tokens, stop_words = ()):\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens\n",
    "\n",
    "def lemmatize_sentence(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in pos_tag(tokens):\n",
    "        if tag.startswith('NN'):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "        lemmatized_sentence.append(lemmatizer.lemmatize(word, pos))\n",
    "    return lemmatized_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f08912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
